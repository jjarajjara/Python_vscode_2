
## 출력층 설계하기
## 일반적으로 회귀에는 항등 함수를, 분류에는 소프트맥스 함수를 사용한다
## 항등 함수 : 입력을 그대로 출력한다
## 소프트맥스 함수 : 입력 신호를 정규화하여 출력한다

## 기계학습 문제는 분류(classification)와 회귀(regression)로 나눌 수 있다
## 분류(classification) : 데이터가 어느 클래스에 속하느냐 문제
## 회귀(regression) : 입력 데이터에서 (연속적인) 수치를 예측하는 문제

## 항등 함수(identity function) : 입력을 그대로 출력하는 함수
## 출력층에서 항등 함수를 사용하면 입력 신호가 그대로 출력 신호가 된다

import numpy as np

def identity_function(x):
    return x

## 소프트맥스 함수(softmax function) : 입력 값을 정규화하여 출력한다

def softmax(a):
    exp_a = np.exp(a) ## 지수 함수
    sum_exp_a = np.sum(exp_a) ## 지수 함수의 합
    y = exp_a / sum_exp_a ## 소프트맥스 함수
    
    return y

## 소프트맥스 함수 구현 정리
## 1. 입력 신호 중 최댓값을 빼준다(오버플로 대책)
## 2. exp() 함수를 적용한다
## 3. exp() 함수의 출력을 모두 더한다
## 4. 3의 결과로 나온 값을 분모와 분자로 나눈다

# ## 소프트맥스 함수의 특징
# ## 소프트맥스 함수의 출력은 0에서 1.0 사이의 실수이다

# a = np.array([0.3,2.9,4.0])
# y = softmax(a)
# print(y)
# print(np.sum(y)) ## 소프트맥스 함수의 출력은 0에서 1.0 사이의 실수이다

## 소프트맥스 함수의 출력 총합은 1이다
##  -> 이 성질 덕분에 소프트맥스 함수의 출력을 '확률'로 해석할 수 있다

## 기계 학습의 문제 풀이 학습과 추론의 두 단계
## 학습 : 모델을 학습하하는 것 -> 훈련 데이터를 사용하여 가중치 매개변수를 학습하는 것
## 추론 : 앞서 학습한 모델로 미지의 데이터에 대해서 추론(분류)하는 것

## 신경망에서는 학습 때는 Softmax 함수를 사용하고, 
## 추론 때는 Softmax 함수를 생략하는 것이 일반적이다

